```
LIP: 0039
Title: Introduce sparse Merkle trees
Author: Alessandro Ricottone <alessandro.ricottone@lightcurve.io>
Discussions-To: https://research.lisk.com/t/introduce-sparse-merkle-trees
Status: Draft
Type: Informational
Created: 2021-04-22
Updated: 2021-12-01
```

## Abstract

In this LIP, we specify the sparse Merkle tree implementation for the Lisk protocol and the format for inclusion proofs. A sparse Merkle tree is an authenticated data structure that allows to validate a key-value dataset with a single hash value, the Merkle root. It differs from a regular Merkle tree in that every element of the dataset occupies a fixed position in the tree, given by its key, and the resulting Merkle root depends only on the final dataset and not on the order of insertion.

## Copyright

This LIP is licensed under the [Creative Commons Zero 1.0 Universal](https://creativecommons.org/publicdomain/zero/1.0/).

## Motivation

A sparse Merkle tree (SMT) is a data structure used to accumulate a key-value dataset into a single root [1].  The main differences between SMTs and regular Merkle trees are that in a SMT the final Merkle root does not depend on the order of insertion of the data, since all elements occupy a fixed position in the tree structure (given by the key). SMTs allow for efficient proofs-of-non-inclusion, where the Prover can convince the Verifier that a certain key-value pair is not part of the underlying dataset.

In this LIP, we specify the SMT data structure for the Lisk protocol. We do not describe specific use-cases, which will be presented in other LIPs. We describe the format for inclusion proofs, the verification protocol, and the proof serialization.

## Rationale

### General Description and Properties

For the rest of the LIP, we indicate with `N` the number of elements present in the tree, with `L` the binary length of a key, and with `Log` the base 2 logarithm.

A sparse Merkle tree is an authenticated data structure organized as a tree. Unlike regular Merkle trees (specified in [LIP 0031](https://github.com/LiskHQ/lips/blob/main/proposals/lip-0031.md) for the Lisk protocol), a SMT contains a distinct leaf node for every possible key. Therefore, the size of the tree is exponential in the length of the keys. For example, for 32-byte keys, a SMT contains 2<sup>256</sup> leaves and 256 layers. Such an enormous number of nodes cannot actually be generated and stored, hence the tree is only ''simulated''.

The defining property of a SMT is:

1. **History independence**: the Merkle root is independent of the insertion history and depends only on the final dataset.

The goal of our specification of a SMT is to have the following properties:

2. **Dynamic**: the tree can be updated efficiently, i.e. with `O(Log(N))` operations.
3. **Universal**: the implementation supports efficient inclusion and non-inclusion proofs.
4. **Efficient storage**: only `O(N)` elements are stored explicitly.

It is sufficient that these properties hold when the keys are randomly distributed, but not necessarily attained in general (for example when the keys are chosen adversarially).

We apply the following optimizations, similar to the one defined in the Diem protocol [2]:

1. Each subtree with exactly one non-empty leaf is replaced by the leaf itself.
2. Each subtree containing only empty nodes is replaced by a constant node with hash value equal to `EMPTY_HASH`.

Here, an empty node is a node storing no value (or value=0). A new tree is initialized with all empty nodes. An example of a tree resulting from these optimizations is given in Figure 1.

<img alt="Sparse Merkle tree" src="lip-0039/sparse_merkle_tree.png" width="400">

*Figure 1: a tree consisting of 11 non-empty leaves. Leaf keys (indicated in green) have a length of 1 byte. We show only the first 4 bytes of the node hashes for convenience and we display the keys in their binary representation. âˆ… denotes default empty nodes. Branch nodes do not have a key, but here we indicate in red the common prefix of the leaf nodes below the branch.*

As mentioned, the tree height is `O(Log(N))` if the keys are randomly distributed. It is easy to fulfill this condition by hashing the keys prior to insertion in the tree. The average number of operations needed to update the tree after inserting a node approaches `Log(N)`, while it equals `L` (256 for 32-byte keys) in the worst case (two consecutive leaf nodes differing only on the last binary digit of their key). The additional introduction of extension nodes could eliminate empty nodes and therefore bring the number of operations down to `O(Log(N))` also for the worst case. However, this optimization introduces extra complexity in the non-inclusion proof protocol, and as explained, this drawback is not relevant for randomly distributed keys.

We use proof compression to guarantee that the proof size also scales as `O(Log(N))`.
We only pass non-empty hashes as part of the proof, and include an extra bitmap to indicate which nodes in the proof path are non default empty nodes.
In summary, this construction supports update, proof generation, and verification in `O(Log(N))` operations, with height, number of nodes, and proof length also scaling as `O(Log(N))`.

### Inclusion Proof Protocols

In this section, we introduce some terminology and explain two general protocols for inclusion proofs. The Verifier holds `merkleRoot`, the Merkle root of the tree built from the dataset, and a set of keys, `queryKeys`, for which they wish to obtain an inclusion proof.

An inclusion proof is characterized by the following properties:

*   `queryKeys`: An array of keys whose presence in the dataset has to be verified.
*   `proof`: The proof itself, consisting of 2 parts: `siblingHashes`, `queries`:
    *   `siblingHashes`: An array of bytes necessary to compute the Merkle root.
    *   `queries`: An array of objects, one per key in `queryKeys`. Each object describes the inclusion proof of the corresponding key and contains the following properties:
        *   `key`: A byte value indicating the presence or not of the corresponding key in the tree.
        *   `bitmap`: A byte value whose binary expansion indicates the presence of a branch or leaf node (digit 1) or an empty node (digit 0) in the path from the leaf node to the root (see Figure 2).
        *   `value`: A byte value giving the value of the node associated with `key.`

The protocol for an inclusion proof is similar to the [one specified for regular Merkle trees](https://github.com/LiskHQ/lips/blob/main/proposals/lip-0031.md#proof-of-inclusion-protocol):

*   Verifier: The Verifier knows `merkleRoot` and sends the Prover an array of keys, `queryKeys`, for which they wish to obtain a proof-of-inclusion;
*   Prover:
    *   The Prover finds the leaf node corresponding to each key `k` in `queryKeys` and assigns to each a `query` object with a key, a bitmap, and a value. The bitmap indicates the presence of default empty nodes along the path to the Merkle root. If the node exists, `query.key` is set to `k` and `query.value` to the node value; if the node does not exist, the Prover returns an inclusion proof for another leaf or a default empty node in the path of the `k`. In this case, `query.key` and `query.value` are set to the leaf key and leaf value or to `k` and empty value, respectively.  
    *   The Prover generates `siblingHashes` by merging together the sibling hashes of the single paths in the correct order of application, and transmits the complete proof to the Verifier. The complete proof contains a common array `siblingHashes` and an array `queries`, containing a query object for each key in `queryKeys`, respecting the same order.
*   Verifier: 
    *   The Verifier uses `siblingHashes` to recalculate the Merkle root starting from the leaf nodes derived from `queryKeys` and `queries`, and checks that it equals `merkleRoot`. 
    *   By comparing the original array of `queryKeys` with the keys in the `proof.queries` array, the Verifier checks that all keys in `queryKeys` are present in the tree.

As shown, a non-inclusion proof is generated by providing a proof of inclusion for another leaf or a default empty node in the path of the target leaf node, indicating that there are no other leaves in the subtree (see Figure 2). The protocol for a non-inclusion proof is thus exactly the same as for an inclusion proof, except that in the last step, where:

*   Verifier: 
    *   By comparing the original array of `queryKeys` with the keys in the `proof.queries` array, the Verifier checks that no keys in `queryKeys` are present in the tree.


### Node Batching Optimization

One of the bottlenecks for a fast update of the sparse Merkle tree is the I/O bandwidth to retrieve the nodes from the database. To reduce the number of database accesses, we introduce the following optimization: Instead of storing every node individually, we store all nodes belonging to the same subtree of height `h` 'batched' together; furthermore, only the subtree external nodes are stored, while the internal nodes are computed on the fly whenever the subtree is updated. This allows to reduce the number of databse accesses by a factor `2^h` at the cost of a slightly more complex and computationally expensive update protocol.

In the following section however, we do not implement this optimization and rather focus on the clarity of the specifications.

## Specification

For the rest of this proposal, we define the following constants:

| Name             | Type    | Value       |
| ---------------- |---------| ------------|
| EMPTY_HASH       | bytes   | SHA-256("") |
| LEAF_PREFIX      | bytes   | ascii encoding of "LSK_SMTL_"  |
| BRANCH_PREFIX    | bytes   | ascii encoding of "LSK_SMTB_"  |
| KEY_LENGTH_BYTES | integer | Length of keys in bytes. Set when initializing the data structure |

Each node in the tree has a `data` and a `hash` property. Leaf nodes store the key and value in their data property, while branch nodes store the hashes of the child nodes. Default empty nodes have a constant hash `EMPTY_HASH`. In summary, we define 3 different node types:

```python
@dataclass
class LeafNode:
    key: bytes
    value: bytes

    @property
    def hash(self) -> bytes:
        return hash(LEAF_PREFIX + self.key + self.value)
```
```python
@dataclass
class BranchNode:
    left_hash: bytes
    right_hash: bytes

    @property
    def hash(self) -> bytes:
        return hash(BRANCH_PREFIX + self.left_hash + self.right_hash)
```
```python
@dataclass
class EmptyNode:
    @property
    def hash(self) -> bytes:
        return EMPTY_HASH
```

Here the function `hash` returns the SHA-256 hash of the input. Similar to what we do for regular Merkle trees, we use a different hash function for leaf and branch nodes to protect against second preimage attacks and prefix the hashed data with different constants.
Leaf nodes are ''hardened'' by hashing their keys together with their values; otherwise, in a subtree with only one non-empty node several keys would correspond to the same leaf node.

The Merkle tree is built on top of an underlying dataset consisting of a set of (key, value) tuples. The key fixes the position of each dataset element in the tree: starting from the root, each digit in the binary expansion indicates whether we should follow the left child (next digit is 0) or the right child (next digit is 1), see Figure 1. The length of the key (in bytes) is a fixed constant of the tree, `KEY_LENGTH_BYTES`, larger than 0. The value property must be non-empty.

As explained in the rationale, rather than explicitly creating a full tree, we simulate it by inserting only non-zero leaves into the tree whenever a new data block (a key-value pair) is added to the dataset, using the two optimizations:

1. Each subtree with exactly one non-empty leaf is replaced by the leaf itself.
2. Each subtree containing only empty nodes is replaced by a constant node with hash value equal to `EMPTY_HASH`.


### Root Hash Calculation

The Merkle root of a dataset is computed as follows:

1. The Merkle root of an empty dataset is set to the constant value `EMPTY_HASH`.
2. The Merkle root of a dataset with a single element is set to the leaf hash of that element.
3. Otherwise, the Merkle root is the root of the tree resulting from the update protocol outlined here, where `root` is the current root of the tree and `keys` and `values` are the keys and corresponding values to be inserted.

```python
def update(
    root: bytes,
    keys: list[bytes],
    values: list[bytes],
) -> LeafNode | BranchNode | EmptyNode:

    assert len(keys) == len(values)

    if len(keys) == 0:
        return root

    # We sort the data by their key, so that we can easily split them
    # into two lists later on.
    sorted_data = sorted(zip(keys, values), key=lambda d: d[0])
    keys = [key for key, _ in sorted_data]
    values = [value for _, value in sorted_data]

    root = _update(keys, values, root, 0)
    return root

def _update(
    keys: list[bytes],
    values: list[bytes],
    current_node: LeafNode | BranchNode | EmptyNode,
    height: int,
) -> LeafNode | BranchNode | EmptyNode:
    
    if len(keys) == 0:
        return current_node
    
    # If there is a single key to update, we return a new leaf node if the current node
    # is an empty node or if the current node is a leaf node and with the same key.
    if len(keys) == 1:
        if isinstance(current_node, EmptyNode):
            return LeafNode(keys[0], values[0])
        elif isinstance(current_node, LeafNode) and current_node.key == keys[0]:
            return LeafNode(keys[0], values[0])

    # We split the keys into two lists, depending on whether the key bit at index 
    # equal to height is 0 or 1.
    idx = split_index(keys, height)
    left_keys = keys[:idx] 
    left_values = values[:idx]
    right_keys = keys[idx:] 
    right_values = values[idx:]

    # We calculate the left and right child recursively.
    if isinstance(current_node, EmptyNode):
        left_node = _update(left_keys, left_values, EmptyNode(), height + 1)
        right_node = _update(right_keys, right_values, EmptyNode(), height + 1)
    elif isinstance(current_node, LeafNode):
        if is_bit_set(current_node.key, height):
            left_node = _update(left_keys, left_values, EmptyNode(), height + 1)
            right_node = _update(right_keys, right_values, current_node, height + 1)
        else:
            left_node = _update(left_keys, left_values, current_node, height + 1)
            right_node = _update(right_keys, right_values, EmptyNode(), height + 1)
    elif isinstance(current_node, BranchNode):
        left_node = get_node(current_node.left_hash)
        right_node = get_node(current_node.right_hash)
        left_node = _update(left_keys, left_values, left_node, height + 1)
        right_node = _update(right_keys, right_values, right_node, height + 1)

    return BranchNode(left_node.hash, right_node.hash)
```

Here the function `get_node` returns the node corresponding to the given hash value, for instance by fetching it from a database.
We use the following utility functions:

```python
def split_index(keys: list[bytes], height: int) -> int:
    '''
    This function returns the index of the first key with bit at index height set to 1.
    '''
    for idx, key in enumerate(keys):
        if is_bit_set(key, height):
            return idx
    return len(keys)
```

```python
def is_bit_set(bits: bytes, i: int) -> bool:
    '''
    This function returns true if the i-th bit of bits is 1, false otherwise.
    '''

    shifted = bits[i // 8] << (i % 8)
    BIT_COMP = int.from_bytes(b"\x80", "big")

    return (shifted & BIT_COMP) == BIT_COMP
```

### Removing a Leaf Node

A certain key-value pair can be removed from the tree by deleting the corresponding leaf node and rearranging the affected nodes in the tree. The following protocol can be used to remove a key `key` from the tree.

```python
def remove(root: bytes, key: bytes) -> LeafNode | BranchNode | EmptyNode:
    ancestor_nodes: list[BranchNode] = []
    current_node = root
    h = 0
    current_node_sibling = EmptyNode()

    # Collect all ancestor nodes through traversing the binary expansion by height
    # End of the loop ancestor_nodes has all the branch nodes
    # current_node will be the leaf/node we are looking to remove
    while isinstance(current_node, BranchNode):
        ancestor_nodes.append(current_node)
        if is_bit_set(key, h):
            current_node_sibling = get_node(current_node.left_hash)
            current_node = get_node(current_node.right_hash)
        else:
            current_node_sibling = get_node(current_node.right_hash)
            current_node = get_node(current_node.left_hash)
        h += 1

    # When current_node is empty, nothing to remove
    if isinstance(current_node, EmptyNode):
        return current_node

    # When the input key does not match node key, nothing to remove
    if current_node.key != key:
        return current_node

    bottom_node = EmptyNode()

    if isinstance(current_node_sibling, LeafNode):
        # current_node has a leaf sibling,
        # remove the leaf and move sibling up the tree
        bottom_node = current_node_sibling
        h -= 1
        while h > 0:
            p = ancestor_nodes[h - 1]

            # if one of the children is empty then break the condition
            if p.left_hash != EmptyNode.hash and p.right_hash != EmptyNode.hash:
                break
            h -= 1

    # Finally update all branch nodes in ancestor_nodes.
    # Note that h now is set to the correct height from which nodes have to be updated.
    while h > 0:
        p = ancestor_nodes[h - 1]
        h -= 1

        if is_bit_set(key, h):
            p.right_hash = bottom_node.hash
        else:
            p.left_hash = bottom_node.hash

        bottom_node = p

    root = bottom_node
    return root
```

### Inclusion Proof Construction and Serialization

<img alt="Sparse Merkle tree with proofs" src="lip-0039/sparse_merkle_tree_with_proofs.png" width="400">

*Figure 2: the inclusion proof for <code>queryKeys=[00110101, 00111111, 01011010, 10111000]</code>. Elements of <code>proof.queries</code> are indicated in bold, while elements of <code>proof.siblingHashes</code> are highlighted in red. The complete proof is given by (hash values are shortened to the first 4 bytes and key and bitmap values are hex-encoded):*

```
proof={siblingHashes:[cc956a85, 3c516152, e041e1c0, 6400721e, 3c32b131],
       queries: [
           {key:33, value:4e074085, bitmap:17},
           {key:3f, value:8a8de823, bitmap:37},
           {key:5a, value:bbeebd87, bitmap:07},
           {key:a9, value:9e8e8c37, bitmap:07}]}.
```

*Given these keys and values, the hash of the node can be recomputed. For example, to the leaf node with <code>key=00110011</code> corresponds the hash <code>leafHash(33 || 4e07408562bedb8b60ce05c1decfe3ad16b72230967de01f640b7e4729b49fce) = 00be9f2ec46f47e14965f0cb9903f09bc6fe30244109c7c5310180a2251c75cc</code>.*


#### Proof Construction

The properties and protocol for an inclusion proof have been introduced in the Rationale section, above. In this section, we specify how these properties are calculated. We assume that the queried keys have a fixed length `KEY_LENGTH_BYTES`.

We define the following data structures:

```python
@dataclass
class Query:
    key: bytes
    value: bytes
    bitmap: bytes

    def __post_init__(self) -> None:
        # The binary bitmap is the binary string obtained from the bitmap.
        # We will use it also to keep track of the nodes that have been visited
        # and the current height of the query.
        self.binary_bitmap = binary_expansion(self.bitmap).lstrip("0")
    
    @property
    def height(self) -> int:
        return len(self.binary_bitmap)

    @property
    def binary_path(self) -> str:
        # Convert the key to binary string and take the first self.height digits.
        return binary_expansion(self.key)[:self.height]
```

```python
@dataclass
class QueryProof(Query):
    ancestor_hashes: list[bytes]
    sibling_hashes: list[bytes]
```

```python
@dataclass
class Proof:
    sibling_hashes: list[bytes]
    queries: list[Query]
```

We make use of the following utility functions:

```python
def binary_expansion(key: bytes):
    '''
    Convert a key to its binary representation
    '''
    return f"{int.from_bytes(key, 'big'):0{8*len(key)}b}"
```

```python
def are_sibling_queries(q1: Query, q2: Query) -> bool:
    '''
    This function returns true if two queries are sibling,
    i.e. they point to two sibling nodes, false otherwise.
    '''
    if len(q1.binary_bitmap) != len(q2.binary_bitmap):
        return False

    if q1.binary_key[:q1.height - 1] != q2.binary_key[:q.height - 1]:
        return False

    return q1.binary_key[q1.height - 1] != q.binary_key[q1.height - 1]
```

```python
def insert_query(
    q: Query, queries: list[Query]
) -> list[Query]:
    '''
    This function inserts the a query back in the query list in the correct positon
    to keep the list sorted by longest binary bitmap (bigger height), breaking ties by smaller key.
    This corresponds to a bottom-up left-right ordering of the corresponding leaf nodes.
    We assume that the input queries list is already sorted.
    '''
    if len(queries) == 0:
        return [q]

    # Run a binary search to efficiently find the insertion index.
    low = -1
    high = len(queries)
    while 1 + low < high:
        middle = low + ((high - low) >> 1)
        p = queries[middle]
        if (q.height == p.height and q.key < p.key) or (q.height > p.height):
            high = middle
        else:
            low = middle

    insert_index = high

    if insert_index == len(queries):
        return queries + [q]

    p = queries[insert_index]
    if p.binary_path != q.binary_path: # If another query at the same 
        queries.insert(insert_index, q)

    return queries
```

The following function generates the query response to a single key, including the sibling hashes and the hash of the visited nodes.

```python
def generate_query_proof(query_key: bytes, root: bytes) -> QueryProof:
    ancestor_hashes = []
    sibling_hashes = []
    current_node = get_node(root)
    binary_bitmap = ""

    # Starting from the root, we navigate down the tree.
    h = 0
    while isinstance(current_node, BranchNode):
        ancestor_hashes.append(current_node.hash)
        if is_bit_set(query_key, h):
            sibling_hash = current_node.left_hash
            current_node = get_node(current_node.right_hash)
        else:
            sibling_hash = current_node.right_hash
            current_node = get_node(current_node.left_hash)

        if sibling_hash == EmptyNode.hash:
            binary_bitmap = "0" + binary_bitmap
        else:
            binary_bitmap = "1" + binary_bitmap
            sibling_hashes.append(sibling_hash)
        h += 1

    if isinstance(current_node, EmptyNode):
        # query_key is not part of the tree
        return QueryProof(
            query_key, EMPTY_VALUE, binary_to_bytes(binary_bitmap), ancestor_hashes, sibling_hashes
        )
    # Else current_node is a leaf node
    assert isinstance(current_node, LeafNode)
    ancestor_hashes.append(current_node.hash)
    return QueryProof(
        current_node.key, current_node.value, binary_to_bytes(binary_bitmap), ancestor_hashes, sibling_hashes
    )
```

Note that the first digit of a query bitmap is always a 1, else the tree would have been invalidly constructed (a leaf node can not have an empty node as sibling). As a consequence, the hex encoded value of the query bitmap corresponds to a unique series of digits. 

To generate a complete inclusion proof, several query responses are combined together, and their sibling hashes are merged in a single array.
Given an array of keys `query_keys`, the inclusion proof is obtained from the function `generate_proof`.

```python
def generate_proof(root: bytes, query_keys: list[bytes]) -> Proof:
    if len(query_keys) == 0:
        return Proof([], [])

    query_proofs = [await generate_query_proof(k, root, 0) for k in query_keys]
    # Prepare queries from single query proofs, maintaining original order (same as query keys).
    queries: list[Query] = [Query(sp.key, sp.value, sp.bitmap) for sp in query_proofs]
    # Sort by largest height (bottom first), smaller key (left first).
    query_proofs = sorted(query_proofs, key=lambda q: (-q.height, q.key))
    sibling_hashes: list[bytes] = []
    ancestor_hashes: list[bytes] = [h for q in query_proofs for h in q.ancestor_hashes]

    while len(query_proofs) > 0:
        q = query_proofs.pop(0)
        if q.height == 0:
            continue

        # If the query bitmap indicates the use of a sibling hash,
        # we check that the hash has not been used before and that it's not an ancestor hash,
        # which means that it can be recalculated from the proof.
        # In this case, we add it to the list of sibling hashes.
        if q.binary_bitmap[0] == "1":
            node_hash = q.sibling_hashes.pop()
            if not node_hash in sibling_hashes and not node_hash in ancestor_hashes:
                sibling_hashes.append(node_hash)

        q.binary_bitmap = q.binary_bitmap[1:] # Modifying the binary bitmap also changes the height.
        query_proofs = insert_query(q, query_proofs)

    return Proof(sibling_hashes, queries)
```

#### Proof Verification

To verify the validity of an (non-)inclusion proof, the general strategy is to recalculate the Merkle root starting from the provided proof. On top of this, the Verifier checks that the proof queries corresponds to a (non-)inclusion proof by comparing them to the query keys that were used to generate the proof.

We define a function to verify inclusion proofs, `verify_inclusion_proof`, and a function to verify non-inclusion proofs, `verify_non_inclusion_proof`. Both function just call the `verify` function after checking if the query key has a corresponding proof query giving a (non-)inclusion proof using the `is_inclusion_proof` function.

```python
def is_inclusion_proof(query_key: bytes, query: Query) -> bool:
    return query_key == query.key and query.value != EMPTY_VALUE
```

```python
def verify_inclusion_proof(query_keys: list[bytes], proof: Proof, root: bytes) -> bool:
    # Check that there is a query for each key.
    if len(query_keys) != len(proof.queries):
        return False

    for key, query in zip(query_keys, proof.queries):
        # This is the only difference between an inclusion and a non-inclusion proof.
        if is_inclusion_proof(key, query) == False:
            return False

    return verify(query_keys, proof, root)
```

```python
def verify_non_inclusion_proof(query_keys: list[bytes], proof: Proof, root: bytes) -> bool:
    # Check that there is a query for each key.
    if len(query_keys) != len(proof.queries):
        return False

    for key, query in zip(query_keys, proof.queries):
        # This is the only difference between an inclusion and a non-inclusion proof.
        if is_inclusion_proof(key, query) == True:
            return False
            
    return verify(query_keys, proof, root)
```

```python
def verify(query_keys: list[bytes], proof: Proof, root: bytes) -> bool:
    for key, query in zip(query_keys, proof.queries):
        # The bitmap does not contain extra leading 0s.
        if query.bitmap[0] == 0:
            return False
        if len(key) != KEY_LENGTH_BYTES:
            return False

        # q is an inclusion proof for k or a default empty node.
        if key == query.key:
            continue

        # q is an inclusion proof for another leaf node
        common_prefix = os.path.commonprefix([binary_expansion(query.key), binary_expansion(key)])
        if len(query.binary_bitmap) > len(common_prefix):
            # q does not give an non-inclusion proof for k.
            return False

    filtered_queries = []
    filter: dict[bytes, bool] = {}
    duplicate_queries = {}
    for q in proof.queries:
        # Remove duplicate queries preserving order.
        # This can happen if the same query is given for different query_keys, as for inclusion proofs or non-inclusion proofs pointing to a leaf node
        # or for non-inclusion proofs pointing to the same empty node.
        # To do this, we check the binary path (key binary expansion up to the query height)
        if q.binary_path not in filter:
            filtered_queries.append(q)
            filter[q.binary_path] = True

        # Check that if a key appears in several queries, than these queries are exactly the same.
        if q.key not in duplicate_queries:
            duplicate_queries[q.key] = q
        else:
            duplicate_query = duplicate_queries[q.key]
            if q.key != duplicate_query.key or q.bitmap != duplicate_query.bitmap or q.value != duplicate_query.value:
                return False

    # Finally calculate the root from the provided proof and check that it matches the input Merkle root.
    return calculate_root(proof.sibling_hashes, filtered_queries) == root
```

```python
def calculate_root(sibling_hashes: list[bytes], queries: list[Query]) -> bytes:
    sorted_queries = sorted(queries, key=lambda q: (-q.height, q.key))

    while len(sorted_queries) > 0:
        q = sorted_queries.pop(0)

        # We reached the top of the tree, return merkle root
        if q.height == 0:
            # Check that no extra bits where appended to the bitmap.
            assert len(q.binary_bitmap) == 0
            assert len(sibling_hashes) == 0
            return q.hash

        # we distinguish three cases for the sibling hash:
        # 1. sibling is next element of sorted_queries
        if len(sorted_queries) > 0 and are_sibling_queries(q, sorted_queries[0]):
            sibling_hash = sorted_queries[0].hash
            # We are merging two branches.
            # Check that the bitmap at the merging point is consistent with the nodes type.
            if sorted_queries[0].hash == EMPTY_HASH:
                assert q.binary_bitmap[0] == "0"
            else:
                assert q.binary_bitmap[0] == "1"
            if q.hash == EMPTY_HASH:
                assert sorted_queries[0].binary_bitmap[0] == "0"
            else:
                assert sorted_queries[0].binary_bitmap[0] == "1"

            # Check that the bitmap coincide from the merging point up.
            assert len(q.binary_bitmap) == len(sorted_queries[0].binary_bitmap)
            if len(q.binary_bitmap) > 0:
                assert q.binary_bitmap[1:] == sorted_queries[0].binary_bitmap[1:]

            del sorted_queries[0]
        # 2. sibling is default empty node
        elif q.binary_bitmap[0] == "0":
            sibling_hash = EMPTY_HASH
        # 3. sibling hash comes from sibling_hashes
        elif q.binary_bitmap[0] == "1":
            sibling_hash = sibling_hashes.pop(0)

        d = q.binary_key[q.height - 1]
        if d == "0":
            q.hash = BranchNode(q.hash, sibling_hash).hash
        elif d == "1":
            q.hash = BranchNode(sibling_hash, q.hash).hash

        q.binary_bitmap = q.binary_bitmap[1:]
        sorted_queries = insert_query(q, sorted_queries)

    raise Exception("Can not calculate root hash")
```


#### Proof Serialization

The inclusion proof is serialized according to the specifications defined in [LIP 0027](https://github.com/LiskHQ/lips/blob/main/proposals/lip-0027.md) using the following JSON schema:

```java
proof = {
    "type": "object",
    "required": ["siblingHashes", "queries"],
    "properties": {
        "siblingHashes": {
            "type": "array",
            "items": {"dataType": "bytes"},
            "fieldNumber": 1
        },
        "queries": {
            "type": "array",
            "items": {
                "type": "object",
                "fieldNumber": 2,
                "required": ["key", "value", "bitmap"],
                "properties": {
                    "key": {
                        "dataType": "bytes",
                        "fieldNumber": 1
                    },
                    "value": {
                        "dataType": "bytes",
                        "fieldNumber": 2
                    },
                    "bitmap": {
                        "dataType": "bytes",
                        "fieldNumber": 3
                    },
                }
            }
        }
    }
}
```

## Backwards Compatibility

This proposal does not introduce any fork(s) in the network, as it only defines the specification of sparse Merkle trees in the Lisk protocol.

## References

[1] Rasmus Dahlberg, Tobias Pulls, and Roel Peeters, [Efficient Sparse Merkle Trees](https://eprint.iacr.org/2016/683.pdf)

[2] Jellyfish Merkle tree, github.com/diem/diem/tree/master/storage/jellyfish-merkle/src
